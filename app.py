import streamlit as st
import pandas as pd
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
import google.generativeai as genai
from dotenv import load_dotenv
import os
import re
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
import time
import streamlit as st

try:
    API_KEY = st.secrets["GEMINI_API_KEY"]
except:
    from dotenv import load_dotenv
    load_dotenv()
    import os
    API_KEY = os.getenv("GEMINI_API_KEY")


# è¼‰å…¥ FAQ è³‡æ–™
df = pd.read_csv("twse.csv", encoding='utf-8-sig')
paragraphs = (df["å•é¡Œ"] + " " + df["ç­”æ¡ˆ"]).tolist()

# åµŒå…¥æ¨¡å‹èˆ‡ FAISS
@st.cache_resource
def load_model_and_index():
    model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
    embeddings = model.encode(paragraphs, convert_to_numpy=True)
    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(embeddings)
    return model, index

embed_model, index = load_model_and_index()

# æª¢ç´¢å‡½æ•¸
def semantic_retrieve(query, k=2):
    query_vec = embed_model.encode([query], convert_to_numpy=True)
    D, I = index.search(query_vec, k)
    return [paragraphs[i] for i in I[0]]

def extract_url(text):
    urls = re.findall(r'https?://[^\s\)]+', text)
    return urls[0] if urls else None

def fetch_dynamic_url_text(url, wait_time=3):
    options = Options()
    options.add_argument('--headless')
    options.add_argument('--disable-gpu')
    options.add_argument('--no-sandbox')

    driver = webdriver.Chrome(options=options)
    driver.get(url)
    time.sleep(wait_time)

    text = ""
    try:
        # å„ªå…ˆæŠ“ä¸»å…§å®¹å€ï¼ˆå¯èƒ½æ˜¯ä¸»è¦æ®µè½ï¼‰
        for tag_name in ["main", "article", "div", "section"]:
            try:
                element = driver.find_element("tag name", tag_name)
                if len(element.text.strip()) > 200:
                    text = element.text
                    break
            except:
                continue

        # fallback æŠ“ body
        if not text.strip():
            text = driver.find_element("tag name", "body").text

    finally:
        driver.quit()

    return text[:2000] + "..." if len(text) > 2000 else text


def summarize_text(text, model=None):
    if not model or not text.strip():
        return text[:300] + "..."  # fallback

    try:
        prompt = (
            f"ã€ç¶²ç«™è³‡æ–™ã€‘ï¼š\n{text}\n\nã€æ‘˜è¦ã€‘ï¼š"
        )
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        print("âŒ è£œå……è³‡æ–™æ‘˜è¦å¤±æ•—ï¼š", e)
        return text[:300] + "..."

# prompt çµ„åˆ
def build_prompt(query, contexts):
    prompt = (
        "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„é‡‘èæŠ•è³‡é¡§å•ï¼Œè«‹æ ¹æ“šä¸‹åˆ—è³‡æ–™å›ç­”ä½¿ç”¨è€…çš„å•é¡Œã€‚\n\n"
        "è«‹æ³¨æ„ï¼š\n"
        "- åƒ…æ ¹æ“šæä¾›è³‡æ–™ä½œç­”ï¼Œä¸è¦ç·¨é€ æˆ–æ¨æ¸¬ã€‚\n"
        "- è‹¥è³‡æ–™ä¸è¶³ï¼Œè«‹æ˜ç¢ºèªªæ˜ã€Œç›®å‰è³‡æ–™ä¸­ç„¡æ³•å›ç­”æ­¤å•é¡Œã€ã€‚\n"
        "- è«‹ä»¥æ¢åˆ—å¼èªªæ˜ï¼Œæ¯é»ç°¡æ½”æ‰¼è¦ï¼Œå¿…è¦æ™‚å¯è£œå……åŸæ–‡ä¸­çš„ç¶²å€ã€‚\n\n"
        "ã€è³‡æ–™æ®µè½ã€‘\n"
    )
    supplement_blocks = []

    for i, ctx in enumerate(contexts):
        prompt += f"{i+1}. {ctx.strip()}\n"
        url = extract_url(ctx)
        if url:
            supplement = fetch_dynamic_url_text(url)
            if supplement:
                summary = summarize_text(supplement, model)
                supplement_blocks.append(f"è£œå……è³‡æ–™ {i+1} ä¾†è‡ª {url}ï¼š\n{summary}")
                
    if supplement_blocks:
        prompt += "\nã€è£œå……è³‡æ–™å€ã€‘\n" + "\n\n".join(supplement_blocks)

    prompt += f"\nã€ä½¿ç”¨è€…æå•ã€‘ï¼š{query}\n\nè«‹æ ¹æ“šä¸Šè¿°è³‡æ–™ï¼Œä»¥æ¢åˆ—å¼å›ç­”ï¼š\n"

    return prompt

genai.configure(api_key=API_KEY)
model = genai.GenerativeModel("gemini-1.5-flash")

st.title("ğŸ’¬ æŠ•è³‡äººæ™ºæ…§å•ç­”(RAG å¼·åŒ–)")

# åˆå§‹åŒ–å°è©±è¨˜æ†¶
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# é¡¯ç¤ºéå»çš„å°è©±
for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ä½¿ç”¨è€…è¼¸å…¥å€
user_input = st.chat_input("è«‹è¼¸å…¥ä½ çš„å•é¡Œ...")

try:
    if user_input:
        # é¡¯ç¤ºä½¿ç”¨è€…è¼¸å…¥
        st.session_state.chat_history.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        # å‘¼å« Gemini å›ç­”
        with st.chat_message("assistant"):
            with st.spinner("æœå°‹çŸ¥è­˜ä¸­..."):
                contexts = semantic_retrieve(user_input)
                prompt = build_prompt(user_input, contexts)
                response = model.generate_content(prompt)
                st.markdown(response.text)

                # é¡¯ç¤ºè£œå……è³‡æ–™ä¾†æº
                for i, ctx in enumerate(contexts):
                    url = extract_url(ctx)
                    if url:
                        supplement = fetch_dynamic_url_text(url)
                        if supplement:
                            st.markdown(f"ğŸ”— è£œå……è³‡æ–™ {i+1}: [{url}]({url})")
                            with st.expander(f"é»æ­¤å±•é–‹è£œå……å…§å®¹ {i+1}"):
                                st.markdown(supplement)

                # åŠ å…¥ AI å›è¦†åˆ°å°è©±æ­·å²
                st.session_state.chat_history.append({"role": "assistant", "content": response.text})
except Exception as e:
     st.error("ç›®å‰ Gemini API å·²é”é…é¡é™åˆ¶ï¼Œè«‹ç¨å¾Œå†è©¦ ğŸ™\n\n + str(e)")
